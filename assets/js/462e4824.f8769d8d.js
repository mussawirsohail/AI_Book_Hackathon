"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[6012],{3845:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>i,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"modules/module-3-ai-brain/lesson-3-isaac-ros-nav2","title":"Lesson 3: Isaac ROS and Nav2: Path Planning for Bipedal Humanoid Movement","description":"Introduction to Navigation in Humanoid Robotics","source":"@site/docs/modules/module-3-ai-brain/lesson-3-isaac-ros-nav2.md","sourceDirName":"modules/module-3-ai-brain","slug":"/modules/module-3-ai-brain/lesson-3-isaac-ros-nav2","permalink":"/AI_Book_Hackathon/docs/modules/module-3-ai-brain/lesson-3-isaac-ros-nav2","draft":false,"unlisted":false,"editUrl":"https://github.com/mussawirsohail/AI_Book_Hackathon/docs/modules/module-3-ai-brain/lesson-3-isaac-ros-nav2.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3}}');var a=r(4848),t=r(8453);const i={sidebar_position:3},s="Lesson 3: Isaac ROS and Nav2: Path Planning for Bipedal Humanoid Movement",l={},c=[{value:"Introduction to Navigation in Humanoid Robotics",id:"introduction-to-navigation-in-humanoid-robotics",level:2},{value:"Overview of Nav2 Architecture",id:"overview-of-nav2-architecture",level:2},{value:"Standard Nav2 Components",id:"standard-nav2-components",level:3},{value:"Isaac ROS Navigation Acceleration",id:"isaac-ros-navigation-acceleration",level:2},{value:"Isaac ROS Perception for Navigation",id:"isaac-ros-perception-for-navigation",level:3},{value:"Footstep Planning for Bipedal Robots",id:"footstep-planning-for-bipedal-robots",level:2},{value:"Footstep Planner Node",id:"footstep-planner-node",level:3},{value:"Integration with Isaac Sim for Humanoid Navigation",id:"integration-with-isaac-sim-for-humanoid-navigation",level:2},{value:"Isaac Sim Humanoid Navigation Setup",id:"isaac-sim-humanoid-navigation-setup",level:3},{value:"Nav2 Configuration for Humanoid Robots",id:"nav2-configuration-for-humanoid-robots",level:2},{value:"Isaac ROS Hardware Acceleration",id:"isaac-ros-hardware-acceleration",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"lesson-3-isaac-ros-and-nav2-path-planning-for-bipedal-humanoid-movement",children:"Lesson 3: Isaac ROS and Nav2: Path Planning for Bipedal Humanoid Movement"})}),"\n",(0,a.jsx)(e.h2,{id:"introduction-to-navigation-in-humanoid-robotics",children:"Introduction to Navigation in Humanoid Robotics"}),"\n",(0,a.jsx)(e.p,{children:"Navigation for bipedal humanoid robots presents unique challenges compared to wheeled robots. Humanoids must consider dynamic stability, balance, footstep planning, and complex kinematics. This lesson covers how Isaac ROS and Nav2 can be adapted for humanoid navigation."}),"\n",(0,a.jsx)(e.h2,{id:"overview-of-nav2-architecture",children:"Overview of Nav2 Architecture"}),"\n",(0,a.jsx)(e.p,{children:"Nav2 (Navigation 2) is the navigation stack for ROS 2, providing path planning, obstacle avoidance, and motion control. For humanoid robots, Nav2 requires special considerations:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Footstep planning instead of simple pose control"}),"\n",(0,a.jsx)(e.li,{children:"Dynamic balance constraints"}),"\n",(0,a.jsx)(e.li,{children:"Complex kinematic chains"}),"\n",(0,a.jsx)(e.li,{children:"Multi-contact planning"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"standard-nav2-components",children:"Standard Nav2 Components"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-yaml",children:"# Example Nav2 configuration for humanoid robot\r\nbt_navigator:\r\n  ros__parameters:\r\n    use_sim_time: True\r\n    global_frame: map\r\n    robot_base_frame: base_link\r\n    plugin_lib_names:\r\n      - nav2_compute_path_to_pose_action_bt_node\r\n      - nav2_compute_path_through_poses_action_bt_node\r\n      - nav2_follow_path_action_bt_node\r\n      - nav2_spin_action_bt_node\r\n      - nav2_wait_action_bt_node\r\n      - nav2_clear_costmap_service_bt_node\r\n      - nav2_is_stuck_condition_bt_node\r\n      - nav2_goal_reached_condition_bt_node\r\n      - nav2_goal_updated_condition_bt_node\r\n      - nav2_initial_pose_received_condition_bt_node\r\n      - nav2_reinitialize_global_localization_service_bt_node\r\n      - nav2_rate_controller_bt_node\r\n      - nav2_distance_controller_bt_node\r\n      - nav2_speed_controller_bt_node\r\n      - nav2_truncate_path_action_bt_node\r\n      - nav2_goal_updater_node_bt_node\r\n      - nav2_recovery_node_bt_node\r\n      - nav2_pipeline_sequence_bt_node\r\n      - nav2_round_robin_node_bt_node\r\n      - nav2_transform_available_condition_bt_node\r\n      - nav2_time_expired_condition_bt_node\r\n      - nav2_path_expiring_timer_condition\r\n      - nav2_distance_traveled_condition_bt_node\n"})}),"\n",(0,a.jsx)(e.h2,{id:"isaac-ros-navigation-acceleration",children:"Isaac ROS Navigation Acceleration"}),"\n",(0,a.jsx)(e.p,{children:"Isaac ROS enhances Nav2 with hardware acceleration for perception and planning tasks:"}),"\n",(0,a.jsx)(e.h3,{id:"isaac-ros-perception-for-navigation",children:"Isaac ROS Perception for Navigation"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image, PointCloud2\r\nfrom geometry_msgs.msg import PoseStamped, Twist\r\nfrom nav_msgs.msg import OccupancyGrid, Path\r\nfrom visualization_msgs.msg import Marker, MarkerArray\r\nfrom tf2_ros import TransformListener, Buffer\r\nimport tf2_geometry_msgs\r\nimport numpy as np\r\n\r\nclass IsaacHumanoidNavigator(Node):\r\n    def __init__(self):\r\n        super().__init__('isaac_humanoid_navigator')\r\n        \r\n        # Isaac-accelerated perception\r\n        self.depth_sub = self.create_subscription(\r\n            Image,\r\n            '/camera/depth/image_rect_raw',\r\n            self.depth_callback,\r\n            10\r\n        )\r\n        \r\n        self.rgb_sub = self.create_subscription(\r\n            Image,\r\n            '/camera/rgb/image_rect_color',\r\n            self.rgb_callback,\r\n            10\r\n        )\r\n        \r\n        # Navigation publishers\r\n        self.path_pub = self.create_publisher(Path, '/humanoid_plan', 10)\r\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\r\n        \r\n        # TF listener for transforms\r\n        self.tf_buffer = Buffer()\r\n        self.tf_listener = TransformListener(self.tf_buffer, self)\r\n        \r\n        # Initialize Isaac perception backend\r\n        self.initialize_isaac_perception()\r\n        \r\n        # State variables\r\n        self.current_goal = None\r\n        self.current_path = None\r\n        \r\n    def initialize_isaac_perception(self):\r\n        self.get_logger().info('Initializing Isaac-accelerated perception')\r\n        # Initialize Isaac perception pipelines here\r\n        \r\n    def depth_callback(self, msg):\r\n        # Process depth data using Isaac-accelerated pipelines\r\n        # This would use Isaac's CUDA-accelerated depth processing\r\n        pass\r\n        \r\n    def rgb_callback(self, msg):\r\n        # Process RGB data for obstacle detection using Isaac\r\n        # This would use Isaac's accelerated computer vision\r\n        pass\r\n        \r\n    def plan_humanoid_path(self, start_pose, goal_pose):\r\n        # Custom path planning for humanoid considering:\r\n        # 1. Reachable space for bipedal movement\r\n        # 2. Balance constraints\r\n        # 3. Footstep planning\r\n        path = self.compute_footstep_path(start_pose, goal_pose)\r\n        return path\r\n        \r\n    def compute_footstep_path(self, start_pose, goal_pose):\r\n        # Simplified footstep planner (in practice, this would be more complex)\r\n        # This would integrate with actual humanoid kinematics\r\n        path = Path()\r\n        path.header.frame_id = \"map\"\r\n        path.header.stamp = self.get_clock().now().to_msg()\r\n        \r\n        # Calculate intermediate waypoints\r\n        steps = 10  # Number of footsteps\r\n        step_size = 0.3  # Distance between footsteps in meters\r\n        \r\n        start_pos = np.array([start_pose.pose.position.x, start_pose.pose.position.y])\r\n        goal_pos = np.array([goal_pose.pose.position.x, goal_pose.pose.position.y])\r\n        direction = goal_pos - start_pos\r\n        distance = np.linalg.norm(direction)\r\n        unit_direction = direction / distance\r\n        \r\n        # Generate footstep positions\r\n        for i in range(steps):\r\n            ratio = i / (steps - 1) if steps > 1 else 0\r\n            pos = start_pos + ratio * (goal_pos - start_pos)\r\n            \r\n            pose_stamped = PoseStamped()\r\n            pose_stamped.header.frame_id = \"map\"\r\n            pose_stamped.pose.position.x = float(pos[0])\r\n            pose_stamped.pose.position.y = float(pos[1])\r\n            pose_stamped.pose.position.z = 0.0  # Ground level\r\n            \r\n            # Set orientation\r\n            pose_stamped.pose.orientation = start_pose.pose.orientation\r\n            \r\n            path.poses.append(pose_stamped)\r\n            \r\n        return path\n"})}),"\n",(0,a.jsx)(e.h2,{id:"footstep-planning-for-bipedal-robots",children:"Footstep Planning for Bipedal Robots"}),"\n",(0,a.jsx)(e.p,{children:"Humanoid robots require specialized planning that considers foot placement and balance:"}),"\n",(0,a.jsx)(e.h3,{id:"footstep-planner-node",children:"Footstep Planner Node"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom geometry_msgs.msg import Pose, Point\r\nfrom visualization_msgs.msg import Marker\r\nimport numpy as np\r\n\r\nclass FootstepPlanner(Node):\r\n    def __init__(self):\r\n        super().__init__('footstep_planner')\r\n        \r\n        self.footstep_pub = self.create_publisher(Marker, '/footsteps', 10)\r\n        self.goal_sub = self.create_subscription(\r\n            Pose,\r\n            '/goal_pose',\r\n            self.goal_callback,\r\n            10\r\n        )\r\n        \r\n        # Humanoid-specific parameters\r\n        self.step_length = 0.3  # meters\r\n        self.step_width = 0.2   # meters (distance between feet)\r\n        self.max_step_turn = 0.5  # radians\r\n        \r\n    def goal_callback(self, goal_pose):\r\n        # Plan footsteps from current position to goal_pose\r\n        footsteps = self.plan_footsteps(goal_pose)\r\n        self.visualize_footsteps(footsteps)\r\n        \r\n    def plan_footsteps(self, goal_pose):\r\n        # Calculate footstep sequence to reach goal\r\n        # This is a simplified example\r\n        footsteps = []\r\n        \r\n        # For demonstration, assume current position is at origin\r\n        current_pos = Point()\r\n        current_pos.x = 0.0\r\n        current_pos.y = 0.0\r\n        current_pos.z = 0.0\r\n        \r\n        # Calculate distance and direction to goal\r\n        dx = goal_pose.position.x - current_pos.x\r\n        dy = goal_pose.position.y - current_pos.y\r\n        distance = np.sqrt(dx**2 + dy**2)\r\n        \r\n        # Calculate number of steps needed\r\n        num_steps = int(distance / self.step_length) + 1\r\n        \r\n        for i in range(num_steps):\r\n            ratio = i / num_steps if num_steps > 0 else 0\r\n            \r\n            # Calculate step position (with zigzag pattern for bipedal)\r\n            step_x = current_pos.x + ratio * dx\r\n            step_y = current_pos.y + ratio * dy\r\n            \r\n            # Add slight zigzag to simulate bipedal movement\r\n            if i % 2 == 0:\r\n                step_y += self.step_width / 2  # Right foot\r\n            else:\r\n                step_y -= self.step_width / 2  # Left foot\r\n                \r\n            foot_pose = Pose()\r\n            foot_pose.position.x = step_x\r\n            foot_pose.position.y = step_y\r\n            foot_pose.position.z = 0.0  # Ground level\r\n            footsteps.append(foot_pose)\r\n            \r\n        return footsteps\r\n        \r\n    def visualize_footsteps(self, footsteps):\r\n        marker = Marker()\r\n        marker.header.frame_id = \"map\"\r\n        marker.header.stamp = self.get_clock().now().to_msg()\r\n        marker.ns = \"footsteps\"\r\n        marker.id = 0\r\n        marker.type = Marker.LINE_STRIP\r\n        marker.action = Marker.ADD\r\n        \r\n        # Set the frame ID and timestamp\r\n        marker.pose.orientation.w = 1.0\r\n        \r\n        # Set the scale of the marker\r\n        marker.scale.x = 0.02  # Line width\r\n        \r\n        # Set the color\r\n        marker.color.r = 1.0\r\n        marker.color.g = 0.0\r\n        marker.color.b = 0.0\r\n        marker.color.a = 1.0\r\n        \r\n        # Add points for each footstep\r\n        for foot_pose in footsteps:\r\n            marker.points.append(foot_pose.position)\r\n            \r\n        self.footstep_pub.publish(marker)\n"})}),"\n",(0,a.jsx)(e.h2,{id:"integration-with-isaac-sim-for-humanoid-navigation",children:"Integration with Isaac Sim for Humanoid Navigation"}),"\n",(0,a.jsx)(e.p,{children:"Simulating humanoid navigation requires detailed physics and collision models:"}),"\n",(0,a.jsx)(e.h3,{id:"isaac-sim-humanoid-navigation-setup",children:"Isaac Sim Humanoid Navigation Setup"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import omni\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.robots import Robot\r\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\r\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\r\nfrom omni.isaac.core.utils.prims import get_prim_at_path\r\nfrom omni.isaac.core.prims import RigidPrimView\r\nfrom omni.isaac.core.objects import DynamicCuboid\r\nimport numpy as np\r\n\r\nclass IsaacHumanoidSimulation:\r\n    def __init__(self):\r\n        self.world = World(stage_units_in_meters=1.0)\r\n        self.humanoid_robot = None\r\n        self.setup_environment()\r\n        \r\n    def setup_environment(self):\r\n        # Get Isaac assets\r\n        assets_root_path = get_assets_root_path()\r\n        if assets_root_path is None:\r\n            print("Could not find Isaac Sim assets")\r\n            return\r\n            \r\n        # Add a humanoid robot (using a generic robot for now)\r\n        # In practice, this would be a detailed humanoid model\r\n        add_reference_to_stage(\r\n            usd_path=assets_root_path + "/Isaac/Robots/Carter/carter_nucleus.usd",\r\n            prim_path="/World/Robot"\r\n        )\r\n        \r\n        # Add obstacles\r\n        obstacle1 = DynamicCuboid(\r\n            prim_path="/World/obstacle1",\r\n            name="obstacle1",\r\n            position=np.array([1.0, 1.0, 0.25]),\r\n            size=0.5,\r\n            color=np.array([0.8, 0.2, 0.1])\r\n        )\r\n        \r\n        obstacle2 = DynamicCuboid(\r\n            prim_path="/World/obstacle2",\r\n            name="obstacle2", \r\n            position=np.array([2.0, -1.0, 0.25]),\r\n            size=0.5,\r\n            color=np.array([0.2, 0.8, 0.1])\r\n        )\r\n        \r\n        # Add ground plane\r\n        self.world.scene.add_ground_plane("ground", \r\n                                          static_friction=0.7,\r\n                                          dynamic_friction=0.5,\r\n                                          restitution=0.8)\r\n        \r\n        # Initialize the world\r\n        self.world.reset()\r\n        \r\n    def run_navigation_simulation(self):\r\n        # This would run a complete navigation task\r\n        # The humanoid would plan a path and execute it\r\n        for i in range(1000):  # Run for 1000 simulation steps\r\n            self.world.step(render=True)\r\n            \r\n            # At some interval, check for navigation commands\r\n            if i % 100 == 0:\r\n                self.execute_navigation_step()\r\n                \r\n    def execute_navigation_step(self):\r\n        # This would interface with the ROS navigation stack\r\n        # that\'s running in the simulation\r\n        pass\n'})}),"\n",(0,a.jsx)(e.h2,{id:"nav2-configuration-for-humanoid-robots",children:"Nav2 Configuration for Humanoid Robots"}),"\n",(0,a.jsx)(e.p,{children:"Nav2 needs specific configuration for humanoid movement patterns:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-yaml",children:'# Example Nav2 configuration for a humanoid robot\r\nlocal_costmap:\r\n  local_costmap:\r\n    ros__parameters:\r\n      update_frequency: 5.0\r\n      publish_frequency: 2.0\r\n      global_frame: odom\r\n      robot_base_frame: base_link\r\n      use_sim_time: True\r\n      rolling_window: true\r\n      width: 6\r\n      height: 6\r\n      resolution: 0.05\r\n      robot_radius: 0.3  # Radius of the humanoid robot\r\n      plugins: ["obstacle_layer", "inflation_layer"]\r\n      inflation_layer:\r\n        plugin: "nav2_costmap_2d::InflationLayer"\r\n        inflation_radius: 0.5  # Inflate humanoids need more space\r\n        cost_scaling_factor: 3.0\r\n        \r\nglobal_costmap:\r\n  global_costmap:\r\n    ros__parameters:\r\n      update_frequency: 1.0\r\n      publish_frequency: 1.0\r\n      global_frame: map\r\n      robot_base_frame: base_link\r\n      use_sim_time: True\r\n      robot_radius: 0.3\r\n      plugins: ["static_layer", "obstacle_layer", "inflation_layer"]\r\n      inflation_layer:\r\n        plugin: "nav2_costmap_2d::InflationLayer"\r\n        inflation_radius: 0.5\r\n        cost_scaling_factor: 3.0\r\n\r\ncontroller_server:\r\n  ros__parameters:\r\n    use_sim_time: True\r\n    controller_frequency: 20.0\r\n    min_x_velocity_threshold: 0.001\r\n    min_y_velocity_threshold: 0.5\r\n    min_theta_velocity_threshold: 0.001\r\n    progress_checker_plugins: ["progress_checker"]\r\n    goal_checker_plugins: ["general_goal_checker"] \r\n    controller_plugins: ["FollowPath"]\r\n    \r\n    # Humanoid-specific controllers would go here\r\n    FollowPath:\r\n      plugin: "nav2_mppi_controller::MPPIController"\r\n      time_steps: 50\r\n      model_dt: 0.05\r\n      no_samples: 100\r\n      motion_model: "DiffDrive"\r\n      x_std: 0.1\r\n      y_std: 0.1\r\n      theta_std: 0.2\r\n      control_duration: 0.1\r\n      cmd_vel_limits: ["-0.5", "0.5", "-0.2", "0.2"]\r\n      transform_tolerance: 0.3\r\n      xy_goal_tolerance: 0.25  # More tolerance for humanoid\r\n      yaw_goal_tolerance: 0.25\r\n      state_bounds_warning: ["-1", "1", "-1", "1", "-1.57", "1.57", "-1.57", "1.57", "-1.57", "1.57", "-3", "3", "-3", "3", "-3", "3"]\n'})}),"\n",(0,a.jsx)(e.h2,{id:"isaac-ros-hardware-acceleration",children:"Isaac ROS Hardware Acceleration"}),"\n",(0,a.jsx)(e.p,{children:"Isaac ROS packages are optimized for GPU acceleration:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image\r\nfrom vision_msgs.msg import Detection2D, Detection2DArray\r\nfrom geometry_msgs.msg import Point\r\nimport numpy as np\r\n\r\nclass IsaacAcceleratedPerception(Node):\r\n    def __init__(self):\r\n        super().__init__('isaac_accelerated_perception')\r\n        \r\n        # Subscribe to camera feed\r\n        self.image_sub = self.create_subscription(\r\n            Image,\r\n            '/camera/rgb/image_rect_color',\r\n            self.image_callback,\r\n            10\r\n        )\r\n        \r\n        # Publish detections\r\n        self.detection_pub = self.create_publisher(\r\n            Detection2DArray,\r\n            '/isaac_detections',\r\n            10\r\n        )\r\n        \r\n        # Initialize Isaac accelerated perception models\r\n        self.initialize_detection_model()\r\n        \r\n    def initialize_detection_model(self):\r\n        # This would initialize Isaac's hardware-accelerated detection models\r\n        # using NVIDIA TensorRT or similar\r\n        self.get_logger().info(\"Isaac Accelerated Perception initialized\")\r\n        \r\n    def image_callback(self, msg):\r\n        # Process image using Isaac's accelerated pipelines\r\n        # This would leverage NVIDIA GPUs for acceleration\r\n        detections = self.detect_objects(msg)\r\n        \r\n        # Publish results\r\n        detection_msg = self.create_detection_message(detections)\r\n        self.detection_pub.publish(detection_msg)\r\n        \r\n    def detect_objects(self, image_msg):\r\n        # This would use Isaac's optimized detection algorithms\r\n        # For demonstration, returning mock detections\r\n        detections = [\r\n            {'class': 'obstacle', 'confidence': 0.95, 'bbox': [100, 100, 50, 50]},\r\n            {'class': 'path', 'confidence': 0.89, 'bbox': [200, 150, 80, 80]}\r\n        ]\r\n        return detections\r\n        \r\n    def create_detection_message(self, detections):\r\n        detection_array = Detection2DArray()\r\n        detection_array.header.stamp = self.get_clock().now().to_msg()\r\n        detection_array.header.frame_id = \"camera_rgb_optical_frame\"\r\n        \r\n        for detection in detections:\r\n            d = Detection2D()\r\n            d.bbox.size_x = detection['bbox'][2]\r\n            d.bbox.size_y = detection['bbox'][3]\r\n            d.bbox.center.x = detection['bbox'][0] + detection['bbox'][2]/2\r\n            d.bbox.center.y = detection['bbox'][1] + detection['bbox'][3]/2\r\n            d.results = [{'score': detection['confidence'], 'class': detection['class']}]\r\n            detection_array.detections.append(d)\r\n            \r\n        return detection_array\n"})}),"\n",(0,a.jsx)(e.p,{children:"In the next module, we'll explore Vision-Language-Action (VLA) systems that combine perception, natural language processing, and action execution to create truly intelligent robotic systems."})]})}function p(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},8453:(n,e,r)=>{r.d(e,{R:()=>i,x:()=>s});var o=r(6540);const a={},t=o.createContext(a);function i(n){const e=o.useContext(t);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:i(n.components),o.createElement(t.Provider,{value:e},n.children)}}}]);